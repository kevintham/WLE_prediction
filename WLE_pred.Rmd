---
title: "Prediction of Human Physical Activity Execution Quality"
author: "Kevin Tham"
date: "May 18, 2018"
output:
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
if (!require("pacman"))
  install.packages("pacman", repos = "http://cran.us.r-project.org")
pacman::p_load(knitr, dplyr, ggplot2, GGally, tidyr, car, broom, tibble, caret, data.table, xgboost, class)
```

```{r}
url1 <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
url2 <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
destfile1 <- 'pml-training.csv'
destfile2 <- 'pml-testing.csv'
  
if (!file.exists(destfile1))
  download.file(url1, destfile1, method = "auto")
if (!file.exists(destfile2))
  download.file(url2, destfile2, method = "auto")

train <- fread(destfile1, na.strings = c("NA", "", "#DIV/0!"))
test <- fread(destfile2, na.strings = c("NA", "", "#DIV/0!"))

ggplot(train, aes(x=cvtd_timestamp,y=classe)) + geom_boxplot()
ggplot(train, aes(x=classe,y=user_name)) + geom_boxplot()


ytrain <- as.factor(train$classe)
ytest <- as.factor(test$classe)

train <- train[,-160]
test <- test[,-160]

nrows <- dim(train)[1]
dim(test)

```

```{r}
na_count <- sapply(train, function(y) sum(is.na(y)))

nacols <- which(na_count>100)
train <- select(train, -nacols)
test <- select(test, -nacols)

str(train)

train <- select(train, -c(1:7))
test <- select(test, -c(1:7))
```

```{r}
set.seed(100)

trainmat <- model.matrix(~.-1,train)

outfolds <- 5
nfolds <- createFolds(ytrain, k=outfolds)

nestedFolds <- function(nfolds) {
  n <- length(nfolds)
  
  nestfolds <- list()
  for (i in 1:n) {
    nestfolds[[i]] <- nfolds[-i]
  }
  nestfolds
}


nestfolds <- nestedFolds(nfolds)
```

```{r}
xgb.predmult <- function(train,label,params,nrounds,test) {
  xgbmod <- xgboost(train,as.numeric(label)-1,params=params,nrounds=nrounds)
  predlong <- predict(xgbmod, test)
  nrows <- dim(test)[1]
  predmat <- matrix(predlong,nrow=nrows,byrow=TRUE)
  predmat
}

# testing
#head(xgb.predmult(trainmat[-nfolds[[1]],], ytrain[-nfolds[[1]]], paramslist,10, trainmat[nfolds[[1]],]))
```

```{r}
knn.predmult <- function(train,label,k,test) {
  knnmod <- knn(train, test, label, k)
  predmat <- model.matrix(~.-1, data=data.frame('y'=knnmod))
}

# testing
#head(knn.predmult(trainmat[-nfolds[[1]],], ytrain[-nfolds[[1]]], 5, trainmat[nfolds[[1]],]))
```



```{r, eval=FALSE}
paramslist <- list('objective'='multi:softprob', 'num_class'=5)
knn.k <- 5
nrounds <- 10

for (k in 1:outfolds) {
  
  meta <- NULL
  cvindex <- nfolds[[k]]
  
  for (l in 1:(outfolds-1)) {
    
    testindex <- nestfolds[[k]][[l]]
    
    trainmatcv <- trainmat[-cvindex,]
    ytraincv <- ytrain[-cvindex]
    
    foldtest <- trainmatcv[testindex,]
    foldtesty <- ytraincv[testindex]
    foldtrain <- trainmatcv[-testindex,]
    foldtrainy <- ytraincv[-testindex]
    
    meta1 <- xgb.predmult(foldtrain,foldtrainy,params=paramslist,nrounds=nrounds,foldtest)
    meta2 <- knn.predmult(foldtrain,foldtrainy,k=knn.k,foldtest)
    
    submeta <- cbind(meta1,meta2)
    meta <- rbind(meta,submeta)
    
  }
  
  
  
}

```

```{r}
#cvxg <- train(train, ytrain, method='xgboost')
#cvxg <- xgb.cv(params=list('objective'='multi:softprob','eval_metric'='mlogloss','num_class'=5), xgtrain, nrounds=500, nfold=5, label=as.numeric(ytrain)-1, print_every_n=10,early_stopping_rounds = 10)

#cvxg <- xgboost(trainmat, label=as.numeric(ytrain)-1, params=list('objective'='multi:softprob', 'num_class'=5),  nrounds=100)

```

```{r, eval=FALSE}
trainpredlong <- predict(cvxg,xgtrain)
trainpredvec <- matrix(trainpredlong, nrow=nrows,byrow=TRUE)

dim(trainpredvec)
trainpred <- apply(trainpredvec, 1,which.max)

trainpred <- factor(trainpred)
levels(trainpred) <- list(A=1,B=2,C=3,D=4,E=5)


confusionMatrix(trainpred, ytrain)
```


```{r, eval=FALSE}
knnmod <- knn(trainmat, trainmat, ytrain, k=5)

confusionMatrix(knnmod, ytrain)
```